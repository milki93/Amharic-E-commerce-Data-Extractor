{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS4KXqBnqQwf"
   },
   "source": [
    "### Clone Repository and Change Directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18775,
     "status": "ok",
     "timestamp": 1750974643777,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "U9mFcxmQPQJh",
    "outputId": "a43933e0-e8f8-4e66-d965-aeaafcbd7104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Amharic-E-commerce-Data-Extractor'...\n",
      "remote: Enumerating objects: 18842, done.\u001b[K\n",
      "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 18842 (delta 19), reused 30 (delta 8), pack-reused 18795 (from 1)\u001b[K\n",
      "Receiving objects: 100% (18842/18842), 106.69 MiB | 9.58 MiB/s, done.\n",
      "Resolving deltas: 100% (2005/2005), done.\n",
      "Updating files: 100% (18556/18556), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/milki93/Amharic-E-commerce-Data-Extractor.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1750974646628,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "5DhhwpvMPSGI",
    "outputId": "bcec9403-d1cf-4fdf-a73f-d42c72b68f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Amharic-E-commerce-Data-Extractor/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Amharic-E-commerce-Data-Extractor/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HFuVrEYpovx"
   },
   "source": [
    "###  Load Dataset Dependencies and Define Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blnPvITkPY1x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load CoNLL Dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import torch\n",
    "\n",
    "conll_file_path = \"/content/Amharic-E-commerce-Data-Extractor/data/labeled_data.conll\"\n",
    "unique_labels = ['O', 'B-Product', 'I-Product', 'B-LOC', 'I-LOC', 'B-PRICE', 'I-PRICE']\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for i, label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw_VM0W9qg_2"
   },
   "source": [
    "### CoNLL File Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DqUTmpgPctY"
   },
   "outputs": [],
   "source": [
    "# Parse CoNLL\n",
    "\n",
    "def parse_conll_file(file_path):\n",
    "    data = []\n",
    "    tokens, ner_tags = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    token, label = parts\n",
    "                    tokens.append(token)\n",
    "                    ner_tags.append(label)\n",
    "            else:\n",
    "                if tokens:\n",
    "                    data.append({\"tokens\": tokens, \"ner_tags\": ner_tags})\n",
    "                tokens, ner_tags = [], []\n",
    "        if tokens:\n",
    "            data.append({\"tokens\": tokens, \"ner_tags\": ner_tags})\n",
    "    return data\n",
    "\n",
    "if os.path.exists(conll_file_path):\n",
    "    loaded_data = parse_conll_file(conll_file_path)\n",
    "    ner_dataset = Dataset.from_list(loaded_data)\n",
    "    split_dataset = ner_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    tokenized_datasets = DatasetDict({\"train\": split_dataset[\"train\"], \"validation\": split_dataset[\"test\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoFP5WuXqx7P"
   },
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "b01a020fbc244ea6ae4904294ef49297",
      "90ad6dd81b2e4b738fd3b4a659c10ae5",
      "579031a9dd004e9faa4c4b83ade084f8",
      "12de7dcfa27d4750b4a7d9d592a190b8",
      "3cd76710a588446daab0f7a6190416be",
      "971cebef793c48028abc4106882c943b",
      "7ca2dd39a4a1437c84357f62763de101",
      "2d31c1e4588a445e9ed87bb4887340d6",
      "f7d82b2d24b348e0a9ebfa8a7b15fcc8",
      "7b18ef9dd69447f8b2a37f5193766350",
      "5ea48ed7556b4f01916b94ed1a8da2c7",
      "e920a6139d5c419ca9d94d8eff424dd3",
      "0902a9878e7a4314b9c73ce62c852267",
      "62b2621d767a471f8bcf2faaa8bb6db1",
      "adeb8344ac494fd8b4a260ce05ede105",
      "ddc6ae4973f44f7dad5fa98fc9ef0d96",
      "9a770061fda84727bd9cffcea14a126e",
      "f920d16ac1c74b2ca739f9c512e16e8d",
      "d340fa8d4c4b490b9f1cc35cf0bb1d95",
      "785f990ef80c4804b569043b5d424e2f",
      "8c3e066f38a6433b87ddc279df3d6a8a",
      "cf0db046c8a341b5ab3bd339b9142736",
      "1dff92a7fc76404fad0cc4f21802f660",
      "d1bafe1bf2754e0eb9d7ed9e53c3e60a",
      "4810cb5333c441f996b88f96f1673ee3",
      "74b50ec36b2a4246876cd640075e1963",
      "3feabf9b9ca741f9a7e37a711db30f96",
      "a803ff05f245474e96c7e51256d7f005",
      "5cafe2db1c3547488ce5be1ebc7ba280",
      "802a9456e852410c869f203b8d0c4e1f",
      "6965f79c6ce5400dbf7563d626b81a10",
      "6610917d85864317bfbbf32f6bad4b41",
      "c3c3f32b82fd4920afda010882040e88",
      "2f27804a83404ab995a12066bd2fee01",
      "a255896f330547308288b2962e8a02c2",
      "77df4db2906044cfb9f48421eae4d0e1",
      "fb33e380b2fa4d028f3b91d8732116a8",
      "b63636115f5e41daa445abd239d8f2e4",
      "003de9b8462c48f48f40c2e84a69c100",
      "949e3765fd024c2e9920018eb47a828a",
      "a95efb26eafc4e08aa7e54029da72449",
      "c28f9a300dc048fea6d216480c515048",
      "32b2cb1593934d64994b664ddee4409f",
      "1e47cbeb2ee54848b87c0e3fde575065"
     ]
    },
    "executionInfo": {
     "elapsed": 9581,
     "status": "ok",
     "timestamp": 1750892298625,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "hxK2typ9PhH0",
    "outputId": "7f51357b-ebfd-4188-ce3d-5d8d30b62c7a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01a020fbc244ea6ae4904294ef49297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e920a6139d5c419ca9d94d8eff424dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dff92a7fc76404fad0cc4f21802f660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f27804a83404ab995a12066bd2fee01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def has_entity_labels(example):\n",
    "    return any(label != 'O' for label in example['ner_tags'])\n",
    "\n",
    "filtered_tokenized_datasets = tokenized_datasets.filter(has_entity_labels)\n",
    "\n",
    "# Load Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"Davlan/afro-xlmr-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Tokenization & Label Alignment\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True, padding=True)\n",
    "    labels = []\n",
    "    for i in range(len(examples[\"tokens\"])):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label = examples[\"ner_tags\"][i]\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label2id[label[word_idx]])\n",
    "            else:\n",
    "                current_label = label[word_idx]\n",
    "                label_ids.append(label2id.get(f\"I-{current_label[2:]}\" if current_label.startswith(\"B-\") else current_label, 0))\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "processed_filtered_dataset = filtered_tokenized_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_tokenized_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fxj15MMFQdQc"
   },
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGSk-2nhq5tM"
   },
   "source": [
    "### Define Weighted Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16660,
     "status": "ok",
     "timestamp": 1750892315328,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "e85QxiOgPtUu",
    "outputId": "9f98a45a-0c83-4b2e-8523-67e0d66488cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "all_labels = list(chain(*tokenized_datasets[\"train\"][\"ner_tags\"]))\n",
    "label_counts = Counter(all_labels)\n",
    "weights = [1.0 / label_counts.get(i, 1) for i in range(len(unique_labels))]\n",
    "weights = torch.tensor(weights, dtype=torch.float)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Define Weighted Model\n",
    "class WeightedTokenClassifier(nn.Module):\n",
    "    def __init__(self, model_checkpoint, num_labels, weight_tensor):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "            model_checkpoint,\n",
    "            num_labels=num_labels,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id\n",
    "        )\n",
    "        self.loss_fct = CrossEntropyLoss(weight=weight_tensor, ignore_index=-100)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "model = WeightedTokenClassifier(model_checkpoint, len(unique_labels), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnyaXK0qR-yl"
   },
   "outputs": [],
   "source": [
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXK5BrysrA1K"
   },
   "source": [
    "### Set Up Training Arguments and Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1750892316138,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "sUjNodELP17L",
    "outputId": "57fb8dc5-a14d-4348-82f9-ec86788bf98b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-11-933359232.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=30,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    true_preds = [[id2label[p] for p, l in zip(pred, label) if l != -100] for pred, label in zip(predictions, labels)]\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_filtered_dataset[\"train\"],\n",
    "    eval_dataset=processed_filtered_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xekL_ZoErGWV"
   },
   "source": [
    "### Initialize Trainer and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 51004,
     "status": "ok",
     "timestamp": 1750896804476,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "QhwyMvdOR3IY",
    "outputId": "ef259eb7-ee84-4db2-83ab-65192ce5c473"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 21:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics: {'eval_loss': 0.4974081516265869, 'eval_precision': 0.5384615384615384, 'eval_recall': 0.4117647058823529, 'eval_f1': 0.4666666666666667, 'eval_runtime': 11.3111, 'eval_samples_per_second': 0.884, 'eval_steps_per_second': 0.177, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_amharic_ner_model/tokenizer_config.json',\n",
       " './fine_tuned_amharic_ner_model/special_tokens_map.json',\n",
       " './fine_tuned_amharic_ner_model/sentencepiece.bpe.model',\n",
       " './fine_tuned_amharic_ner_model/added_tokens.json',\n",
       " './fine_tuned_amharic_ner_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "model_save_path = \"./fine_tuned_amharic_ner_model\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8ck1mzIrdn_"
   },
   "source": [
    "### Save Model to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27446,
     "status": "ok",
     "timestamp": 1750895916234,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "pLzCDfqwSK7h",
    "outputId": "d46086b4-7713-40c4-dc97-da4e496fc3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/amharic_ner_model/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/amharic_ner_model/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/amharic_ner_model/sentencepiece.bpe.model',\n",
       " '/content/drive/MyDrive/amharic_ner_model/added_tokens.json',\n",
       " '/content/drive/MyDrive/amharic_ner_model/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "model.base_model.save_pretrained(\"/content/drive/MyDrive/amharic_ner_model\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/amharic_ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iRnnolwhfm3"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/amharic_ner_model\"\n",
    "\n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GG3FSl8oxHU"
   },
   "source": [
    "### Predict named entities on new, unseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1750897657870,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "PlnUyIQLmLTo",
    "outputId": "25322daf-b5bc-4dd1-c782-40687d78e5c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Predictions on New Text\n",
      "\n",
      "Sentence: አዲስ አበባ ውስጥ ያማረ ሳምሰንግ ስልክ ገዛሁ።\n",
      "  Word: 'አዲስ አበባ' | Entity: Product | Score: 0.34\n",
      "  Word: 'ም' | Entity: LOC | Score: 0.53\n",
      "  Word: 'ንግ' | Entity: LOC | Score: 0.40\n",
      "\n",
      "Sentence: የአይፎን 15 ዋጋ 20,000 ብር ነው?\n",
      "  Word: 'ይ' | Entity: LOC | Score: 0.44\n",
      "\n",
      "Sentence: በ500 ብር ጫማ መግዛት እፈልጋለሁ።\n",
      "  Word: 'ጫ' | Entity: LOC | Score: 0.36\n",
      "\n",
      "Sentence: ኢትዮጵያ ውስጥ ምርጥ ምርት እየፈለግኩ ነው።\n",
      "  No entities detected.\n",
      "\n",
      "Sentence: ዋጋው 300 ብር ሲሆን በአዲስ አበባ እና በአዳማ መላኪያ ይገኛል\n",
      "  Word: '300' | Entity: PRICE | Score: 0.30\n",
      "\n",
      "Sentence: እጅግ በጣም ቆንጆ አይፎን 14 ፕሮ ማክስ በቅናሽ ዋጋ\n",
      "  Word: 'በጣም ቆንጆ አይፎን 14 ፕሮ ማክስ' | Entity: LOC | Score: 0.63\n",
      "\n",
      "Sentence: የአንድሮይድ ስልክ ብራንድ ሳምሰንግ ጋላክሲ A52 በ25,000 ብር\n",
      "  Word: 'የአንድሮይድ ስልክ ብራንድ ሳምሰንግ ጋላክሲ A52' | Entity: LOC | Score: 0.64\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Create a Hugging Face pipeline for token classification\n",
    "ner_pipeline = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Test with some example Amharic sentences\n",
    "test_sentences = [\n",
    "    \"አዲስ አበባ ውስጥ ያማረ ሳምሰንግ ስልክ ገዛሁ።\", # \"I bought a beautiful Samsung phone in Addis Ababa.\"\n",
    "    \"የአይፎን 15 ዋጋ 20,000 ብር ነው?\", # \"Is the iPhone 15 price 20,000 Birr?\"\n",
    "    \"በ500 ብር ጫማ መግዛት እፈልጋለሁ።\", # \"I want to buy shoes for 500 Birr.\"\n",
    "    \"ኢትዮጵያ ውስጥ ምርጥ ምርት እየፈለግኩ ነው።\", # \"I am looking for the best product in Ethiopia.\"\n",
    "    \"ዋጋው 300 ብር ሲሆን በአዲስ አበባ እና በአዳማ መላኪያ ይገኛል\", # \"The price is 300 Birr and delivery is available in Addis Ababa and Adama.\"\n",
    "    \"እጅግ በጣም ቆንጆ አይፎን 14 ፕሮ ማክስ በቅናሽ ዋጋ\", # \"Very beautiful iPhone 14 Pro Max at a discounted price\"\n",
    "    \"የአንድሮይድ ስልክ ብራንድ ሳምሰንግ ጋላክሲ A52 በ25,000 ብር\" # \"Android phone brand Samsung Galaxy A52 for 25,000 Birr\"\n",
    "]\n",
    "\n",
    "print(\"\\n Model Predictions on New Text\")\n",
    "for sentence in test_sentences:\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    predictions = ner_pipeline(sentence)\n",
    "    if predictions:\n",
    "        for pred in predictions:\n",
    "            print(f\"  Word: '{pred['word']}' | Entity: {pred['entity_group']} | Score: {pred['score']:.2f}\")\n",
    "    else:\n",
    "        print(\"  No entities detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJMAQNxEU_TJ"
   },
   "source": [
    "### Mount the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34939,
     "status": "ok",
     "timestamp": 1750974805475,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "CaIxYrAdOkoA",
    "outputId": "c5be0d7b-b086-4336-bb87-b38273b4142e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1750974957810,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "WpKcu_A2Ogqq"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/My Drive/Colab Notebooks/NER_model.ipynb\" /content/Amharic-E-commerce-Data-Extractor/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750975016930,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "J5LSbDAPPYZ2",
    "outputId": "2880992d-6bac-4621-89ee-8ec375e1331b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Amharic-E-commerce-Data-Extractor\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Amharic-E-commerce-Data-Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1750976205686,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "xf2WX9dBT5kv"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"milkidida131@gmail.com\"\n",
    "!git config --global user.name \"milki93\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1750976211232,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "XBHyMuh3RVhz",
    "outputId": "c904558b-d293-4daf-e26a-78441525a010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# github.com:22 SSH-2.0-06447d1b\n",
      "# github.com:22 SSH-2.0-06447d1b\n",
      "# github.com:22 SSH-2.0-06447d1b\n",
      "# github.com:22 SSH-2.0-06447d1b\n",
      "# github.com:22 SSH-2.0-06447d1b\n"
     ]
    }
   ],
   "source": [
    "!ssh-keyscan github.com >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1750976215506,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "Nki3aPN8Reed",
    "outputId": "4bc9c6f9-f18e-4c75-b2cf-4cf4932e6ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi milki93! You've successfully authenticated, but GitHub does not provide shell access.\n"
     ]
    }
   ],
   "source": [
    "!ssh -T git@github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1750976014777,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "VQxJfYaWRjKH"
   },
   "outputs": [],
   "source": [
    "# !cat ~/.ssh/id_ed25519.pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750976222584,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "7hFs8eXKRzcc",
    "outputId": "b41cf64f-663d-45c1-f471-a19acf541dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Amharic-E-commerce-Data-Extractor\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Amharic-E-commerce-Data-Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1750976225362,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "7m5RSReASmdi"
   },
   "outputs": [],
   "source": [
    "!git remote set-url origin git@github.com:milki93/Amharic-E-commerce-Data-Extractor.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1750976228701,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "MSqT253_TBla",
    "outputId": "3f26deb8-0592-4b2f-9c18-ddb1c9c30904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\tnotebooks/NER_model.ipynb\n",
      "Already on 'task-3'\n"
     ]
    }
   ],
   "source": [
    "!git checkout task-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1750976234049,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "Muk7ReuBTKvk"
   },
   "outputs": [],
   "source": [
    "!git add notebooks/NER_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1750976237264,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "0XevwXWxTmsz",
    "outputId": "46221016-0f51-4154-e916-4c17f09d4517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[task-3 aeab228c] Add NER model\n",
      " 1 file changed, 1 insertion(+)\n",
      " create mode 100644 notebooks/NER_model.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Add NER model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1750976262837,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "Km3YogxNTxnF",
    "outputId": "adf7df97-1705-4eef-ef08-deb41e5fb041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 6, done.\n",
      "Counting objects:  16% (1/6)\r",
      "Counting objects:  33% (2/6)\r",
      "Counting objects:  50% (3/6)\r",
      "Counting objects:  66% (4/6)\r",
      "Counting objects:  83% (5/6)\r",
      "Counting objects: 100% (6/6)\r",
      "Counting objects: 100% (6/6), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects:  25% (1/4)\r",
      "Compressing objects:  50% (2/4)\r",
      "Compressing objects:  75% (3/4)\r",
      "Compressing objects: 100% (4/4)\r",
      "Compressing objects: 100% (4/4), done.\n",
      "Writing objects:  25% (1/4)\r",
      "Writing objects:  50% (2/4)\r",
      "Writing objects:  75% (3/4)\r",
      "Writing objects: 100% (4/4)\r",
      "Writing objects: 100% (4/4), 8.83 KiB | 4.41 MiB/s, done.\n",
      "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas:   0% (0/2)\u001b[K\r",
      "remote: Resolving deltas:  50% (1/2)\u001b[K\r",
      "remote: Resolving deltas: 100% (2/2)\u001b[K\r",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "remote: \n",
      "remote: Create a pull request for 'task-3' on GitHub by visiting:\u001b[K\n",
      "remote:      https://github.com/milki93/Amharic-E-commerce-Data-Extractor/pull/new/task-3\u001b[K\n",
      "remote: \n",
      "To github.com:milki93/Amharic-E-commerce-Data-Extractor.git\n",
      " * [new branch]        task-3 -> task-3\n"
     ]
    }
   ],
   "source": [
    "!git push origin task-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1750976525200,
     "user": {
      "displayName": "Milki Dida",
      "userId": "07464085856863573424"
     },
     "user_tz": -180
    },
    "id": "TgiAX3XwUW4x",
    "outputId": "5c71f2d5-adbd-4406-d71c-de2522f253f0"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Javascript('IPython.notebook.save_checkpoint();')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtdvHvrDVXHS"
   },
   "outputs": [],
   "source": [
    "cp \"/content/drive/My Drive/path/to/your_notebook.ipynb\" /content/my-repo/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNy4E68BpAmbaEOpXcFd9sX",
   "provenance": [
    {
     "file_id": "1RihvwoNbDyaPJ-6KRTTxqF6cSgoBGiZZ",
     "timestamp": 1750902013982
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
